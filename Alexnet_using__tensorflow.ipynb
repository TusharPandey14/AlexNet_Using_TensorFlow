{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TusharPandey14/AlexNet_Using_TensorFlow/blob/main/Alexnet_using__tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkP_VWJvwwcJ",
        "outputId": "f361d783-2dc1-4439-ad93-87b31d8bfd01"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/rooms_dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4vXfXvHxFMh",
        "outputId": "6f26bfdf-5c1e-4ce8-f6db-eaea077c01ce"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bed_room  dining_room\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/My Drive/rooms_dataset'\n",
        "print(os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAa8P0HH0UAu",
        "outputId": "94e8781e-81aa-4ad8-d995-ef18c1c06f49"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dining_room', 'bed_room']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "bKt062AurJp8",
        "outputId": "cf70da0a-305f-4319-b735-4282069fce53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Types of rooms found:  37\n"
          ]
        }
      ],
      "source": [
        "print(\"Types of rooms found: \", len(dataset_path))\n",
        "room_types = os.listdir(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "gsOhhuoFrJp9",
        "outputId": "041255b1-f291-450b-e4ed-ceb31b9c5e3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subfolder: dining_room, Number of Images: 86\n",
            "Subfolder: bed_room, Number of Images: 159\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/rooms_dataset'\n",
        "subfolders = os.listdir(dataset_path)\n",
        "\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(dataset_path, subfolder)\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        # Now we can further process images within this subfolder\n",
        "        images_in_subfolder = os.listdir(subfolder_path)\n",
        "        print(f\"Subfolder: {subfolder}, Number of Images: {len(images_in_subfolder)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "zD_fpQS4rJp-",
        "outputId": "929e69c3-5a5c-44f0-a785-7a3dee766485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     room type                                              image\n",
            "0  dining_room  /content/drive/My Drive/rooms_dataset/dining_r...\n",
            "1  dining_room  /content/drive/My Drive/rooms_dataset/dining_r...\n",
            "2  dining_room  /content/drive/My Drive/rooms_dataset/dining_r...\n",
            "3  dining_room  /content/drive/My Drive/rooms_dataset/dining_r...\n",
            "4  dining_room  /content/drive/My Drive/rooms_dataset/dining_r...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Build a dataframe\n",
        "rooms_df = pd.DataFrame(data=rooms, columns=['room type', 'image'])\n",
        "print(rooms_df.head())\n",
        "#print(rooms_df.tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Wvpf4i9srJp_",
        "outputId": "ed488c3d-9a92-4b00-fc6d-bb7404122ad1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rooms in the dataset:  245\n"
          ]
        }
      ],
      "source": [
        "#checking how many samples for each category are present\n",
        "print(\"Total number of rooms in the dataset: \", len(rooms_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Vm9Z_jLDrJqB",
        "outputId": "7e2525d9-dc2f-4420-d5cb-8a6ba5e932a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rooms in each category: \n",
            "bed_room       159\n",
            "dining_room     86\n",
            "Name: room type, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "room_count = rooms_df['room type'].value_counts()\n",
        "\n",
        "print(\"rooms in each category: \")\n",
        "print(room_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "jGKh99fzrJqC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "path = '/content/drive/My Drive/rooms_dataset/'  # Update with your dataset path\n",
        "im_size = 227\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "room_types = os.listdir(path)\n",
        "\n",
        "for room_type in room_types:\n",
        "    data_path = path + room_type + '/'  # Entered the first folder and then the second folder\n",
        "    filenames = [f for f in os.listdir(data_path) if f.endswith('.jpg') or f.endswith('.png')]  # Assuming images are in jpg or png format\n",
        "\n",
        "    for filename in filenames:\n",
        "        img_path = os.path.join(data_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is not None and img.shape[0] > 0 and img.shape[1] > 0:\n",
        "            img = cv2.resize(img, (im_size, im_size))\n",
        "            images.append(img)\n",
        "            labels.append(room_type)\n",
        "        else:\n",
        "            print(f\"Skipped invalid image: {filename}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images, dtype=\"float32\")\n",
        "labels = np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "-pbC8HfXrJqD",
        "outputId": "bc307409-4531-453f-e533-28ed52ff22d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'dining_room', 'dining_room',\n",
              "       'dining_room', 'dining_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room', 'bed_room', 'bed_room', 'bed_room',\n",
              "       'bed_room', 'bed_room'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "sVpxFCZ3rJqF",
        "outputId": "4f1a479f-eded-4f8b-d44f-f1a685d784ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 46., 130., 208.],\n",
              "         [ 45., 130., 208.],\n",
              "         [ 43., 132., 209.],\n",
              "         ...,\n",
              "         [ 79., 157., 227.],\n",
              "         [ 77., 157., 226.],\n",
              "         [ 78., 157., 227.]],\n",
              "\n",
              "        [[ 40., 131., 208.],\n",
              "         [ 40., 132., 210.],\n",
              "         [ 40., 133., 211.],\n",
              "         ...,\n",
              "         [ 77., 156., 228.],\n",
              "         [ 76., 155., 227.],\n",
              "         [ 77., 156., 228.]],\n",
              "\n",
              "        [[ 34., 133., 209.],\n",
              "         [ 35., 133., 211.],\n",
              "         [ 36., 134., 212.],\n",
              "         ...,\n",
              "         [ 76., 155., 228.],\n",
              "         [ 77., 154., 227.],\n",
              "         [ 75., 153., 226.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 18.,  84., 152.],\n",
              "         [ 19.,  85., 152.],\n",
              "         [ 16.,  82., 150.],\n",
              "         ...,\n",
              "         [166., 177., 211.],\n",
              "         [150., 164., 205.],\n",
              "         [148., 161., 199.]],\n",
              "\n",
              "        [[ 20.,  85., 153.],\n",
              "         [ 20.,  84., 152.],\n",
              "         [ 16.,  81., 149.],\n",
              "         ...,\n",
              "         [161., 172., 208.],\n",
              "         [137., 154., 196.],\n",
              "         [151., 165., 205.]],\n",
              "\n",
              "        [[ 19.,  84., 152.],\n",
              "         [ 20.,  85., 153.],\n",
              "         [ 17.,  83., 151.],\n",
              "         ...,\n",
              "         [163., 175., 211.],\n",
              "         [132., 148., 190.],\n",
              "         [157., 172., 212.]]],\n",
              "\n",
              "\n",
              "       [[[  9.,  17.,  40.],\n",
              "         [ 12.,  20.,  43.],\n",
              "         [ 13.,  20.,  45.],\n",
              "         ...,\n",
              "         [ 26.,  53., 166.],\n",
              "         [ 25.,  52., 167.],\n",
              "         [ 31.,  60., 175.]],\n",
              "\n",
              "        [[ 10.,  18.,  41.],\n",
              "         [ 13.,  21.,  44.],\n",
              "         [ 13.,  20.,  45.],\n",
              "         ...,\n",
              "         [ 23.,  51., 165.],\n",
              "         [ 28.,  58., 171.],\n",
              "         [ 32.,  61., 176.]],\n",
              "\n",
              "        [[ 11.,  19.,  42.],\n",
              "         [ 13.,  21.,  44.],\n",
              "         [ 14.,  21.,  46.],\n",
              "         ...,\n",
              "         [ 27.,  56., 170.],\n",
              "         [ 29.,  60., 173.],\n",
              "         [ 35.,  64., 179.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 16.,  26.,  73.],\n",
              "         [ 17.,  26.,  73.],\n",
              "         [ 17.,  26.,  72.],\n",
              "         ...,\n",
              "         [ 11.,  15.,  20.],\n",
              "         [ 11.,  14.,  21.],\n",
              "         [ 11.,  14.,  21.]],\n",
              "\n",
              "        [[ 16.,  24.,  76.],\n",
              "         [ 18.,  26.,  71.],\n",
              "         [ 16.,  27.,  67.],\n",
              "         ...,\n",
              "         [ 11.,  15.,  20.],\n",
              "         [ 11.,  14.,  22.],\n",
              "         [ 11.,  14.,  22.]],\n",
              "\n",
              "        [[ 15.,  23.,  74.],\n",
              "         [ 15.,  24.,  69.],\n",
              "         [ 17.,  27.,  67.],\n",
              "         ...,\n",
              "         [ 11.,  15.,  20.],\n",
              "         [ 11.,  14.,  22.],\n",
              "         [ 11.,  14.,  22.]]],\n",
              "\n",
              "\n",
              "       [[[255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         ...,\n",
              "         [ 95., 107., 117.],\n",
              "         [ 94., 106., 116.],\n",
              "         [ 93., 105., 115.]],\n",
              "\n",
              "        [[255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         ...,\n",
              "         [ 95., 107., 117.],\n",
              "         [ 94., 106., 116.],\n",
              "         [ 93., 105., 115.]],\n",
              "\n",
              "        [[255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         ...,\n",
              "         [ 95., 107., 117.],\n",
              "         [ 95., 107., 117.],\n",
              "         [ 94., 106., 116.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[150., 144., 135.],\n",
              "         [150., 143., 135.],\n",
              "         [144., 140., 132.],\n",
              "         ...,\n",
              "         [119., 115., 116.],\n",
              "         [118., 114., 114.],\n",
              "         [116., 112., 113.]],\n",
              "\n",
              "        [[136., 133., 125.],\n",
              "         [136., 132., 127.],\n",
              "         [121., 118., 113.],\n",
              "         ...,\n",
              "         [120., 115., 116.],\n",
              "         [119., 114., 115.],\n",
              "         [117., 112., 113.]],\n",
              "\n",
              "        [[117., 114., 106.],\n",
              "         [109., 105., 100.],\n",
              "         [134., 131., 126.],\n",
              "         ...,\n",
              "         [120., 115., 116.],\n",
              "         [119., 114., 115.],\n",
              "         [117., 112., 113.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[234., 185., 145.],\n",
              "         [235., 186., 146.],\n",
              "         [236., 187., 147.],\n",
              "         ...,\n",
              "         [219., 170., 138.],\n",
              "         [219., 170., 138.],\n",
              "         [219., 170., 138.]],\n",
              "\n",
              "        [[232., 186., 147.],\n",
              "         [233., 186., 147.],\n",
              "         [233., 186., 148.],\n",
              "         ...,\n",
              "         [219., 170., 138.],\n",
              "         [219., 170., 138.],\n",
              "         [219., 170., 138.]],\n",
              "\n",
              "        [[231., 186., 148.],\n",
              "         [231., 186., 148.],\n",
              "         [231., 186., 148.],\n",
              "         ...,\n",
              "         [220., 171., 139.],\n",
              "         [220., 171., 139.],\n",
              "         [220., 171., 139.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[246., 214., 188.],\n",
              "         [246., 214., 188.],\n",
              "         [245., 214., 189.],\n",
              "         ...,\n",
              "         [237., 198., 173.],\n",
              "         [236., 197., 172.],\n",
              "         [237., 197., 172.]],\n",
              "\n",
              "        [[246., 213., 187.],\n",
              "         [246., 213., 187.],\n",
              "         [245., 213., 188.],\n",
              "         ...,\n",
              "         [237., 198., 173.],\n",
              "         [237., 197., 172.],\n",
              "         [237., 197., 172.]],\n",
              "\n",
              "        [[245., 212., 186.],\n",
              "         [245., 212., 186.],\n",
              "         [244., 212., 187.],\n",
              "         ...,\n",
              "         [237., 197., 172.],\n",
              "         [237., 197., 172.],\n",
              "         [237., 197., 172.]]],\n",
              "\n",
              "\n",
              "       [[[193., 200., 203.],\n",
              "         [193., 200., 203.],\n",
              "         [193., 200., 203.],\n",
              "         ...,\n",
              "         [212., 214., 224.],\n",
              "         [212., 214., 224.],\n",
              "         [212., 214., 224.]],\n",
              "\n",
              "        [[193., 200., 203.],\n",
              "         [193., 200., 203.],\n",
              "         [193., 200., 203.],\n",
              "         ...,\n",
              "         [212., 214., 224.],\n",
              "         [212., 214., 224.],\n",
              "         [212., 214., 224.]],\n",
              "\n",
              "        [[193., 200., 203.],\n",
              "         [193., 200., 203.],\n",
              "         [193., 200., 203.],\n",
              "         ...,\n",
              "         [212., 214., 224.],\n",
              "         [212., 214., 224.],\n",
              "         [212., 214., 224.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 89.,  90.,  80.],\n",
              "         [ 89.,  90.,  80.],\n",
              "         [ 89.,  90.,  80.],\n",
              "         ...,\n",
              "         [229., 238., 235.],\n",
              "         [229., 238., 235.],\n",
              "         [229., 238., 235.]],\n",
              "\n",
              "        [[ 89.,  90.,  80.],\n",
              "         [ 89.,  90.,  80.],\n",
              "         [ 89.,  90.,  80.],\n",
              "         ...,\n",
              "         [229., 238., 235.],\n",
              "         [229., 238., 235.],\n",
              "         [229., 238., 235.]],\n",
              "\n",
              "        [[ 89.,  90.,  80.],\n",
              "         [ 89.,  90.,  80.],\n",
              "         [ 89.,  90.,  80.],\n",
              "         ...,\n",
              "         [229., 238., 235.],\n",
              "         [229., 238., 235.],\n",
              "         [229., 238., 235.]]],\n",
              "\n",
              "\n",
              "       [[[175., 188., 196.],\n",
              "         [173., 185., 195.],\n",
              "         [173., 186., 194.],\n",
              "         ...,\n",
              "         [205., 212., 221.],\n",
              "         [203., 212., 221.],\n",
              "         [203., 212., 221.]],\n",
              "\n",
              "        [[176., 189., 197.],\n",
              "         [174., 186., 196.],\n",
              "         [173., 186., 194.],\n",
              "         ...,\n",
              "         [210., 215., 224.],\n",
              "         [207., 215., 222.],\n",
              "         [207., 215., 222.]],\n",
              "\n",
              "        [[178., 189., 197.],\n",
              "         [177., 187., 197.],\n",
              "         [175., 186., 194.],\n",
              "         ...,\n",
              "         [210., 216., 223.],\n",
              "         [210., 216., 221.],\n",
              "         [210., 216., 221.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 76., 130., 181.],\n",
              "         [ 79., 130., 180.],\n",
              "         [ 79., 132., 182.],\n",
              "         ...,\n",
              "         [167., 184., 223.],\n",
              "         [158., 175., 218.],\n",
              "         [130., 156., 204.]],\n",
              "\n",
              "        [[ 77., 133., 182.],\n",
              "         [ 83., 139., 188.],\n",
              "         [ 82., 135., 185.],\n",
              "         ...,\n",
              "         [162., 180., 221.],\n",
              "         [161., 180., 223.],\n",
              "         [137., 164., 211.]],\n",
              "\n",
              "        [[ 83., 133., 183.],\n",
              "         [ 80., 133., 183.],\n",
              "         [ 78., 134., 181.],\n",
              "         ...,\n",
              "         [161., 183., 224.],\n",
              "         [156., 175., 218.],\n",
              "         [136., 161., 206.]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "b2C7vSSbrJqG",
        "outputId": "cfcf5c37-68c9-427d-9330-a03f84e8f68f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(206, 227, 227, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "# Transform the image array to a numpy type\n",
        "images = np.array(images)\n",
        "images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "OBpUuah6rJqH"
      },
      "outputs": [],
      "source": [
        "images = images.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "ujKfDU7ErJqI",
        "outputId": "a3439c12-61ff-47d4-a9a2-2da54a0b4126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1]\n",
            "(245, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Assuming rooms_df is your DataFrame and 'room type' is the column containing labels\n",
        "y = rooms_df['room type'].values\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "print(y_encoded[:5])\n",
        "\n",
        "# One-hot encoding\n",
        "onehot_encoder = OneHotEncoder()\n",
        "Y = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
        "print(Y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "HqimwjPJrJqJ",
        "outputId": "8dc0dc26-781f-4858-b797-a650d0ac9ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206\n",
            "245\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Number of samples in images and Y are inconsistent.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-0ac9f7bf795e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of samples in images and Y are inconsistent.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of samples in images and Y are inconsistent."
          ]
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming Y is the one-hot encoded labels\n",
        "# Before shuffle, ensure that Y has the same number of samples as images\n",
        "print(len(images))\n",
        "print(Y.shape[0])\n",
        "\n",
        "if len(images) != Y.shape[0]:\n",
        "    raise ValueError(\"Number of samples in images and Y are inconsistent.\")\n",
        "\n",
        "images, Y = shuffle(images, Y, random_state=1)\n",
        "\n",
        "if len(images) != Y.shape[0]:\n",
        "    raise ValueError(\"Number of samples in images and Y are inconsistent.\")\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.05, random_state=415)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "EMv_V3O_rJqJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "# Input placeholder\n",
        "x = tf.keras.layers.Input(shape=(227, 227, 3), dtype=tf.float32)\n",
        "\n",
        "# Output placeholder\n",
        "y_ = tf.keras.layers.Input(shape=(num_classes,), dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "q4aqFWwJrJqK"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "weights = {\n",
        "    'w1': tf.Variable(tf.random.normal([11, 11, 3, 96]), name='w1'),  # 11*11*3   96 filters\n",
        "    'w2': tf.Variable(tf.random.normal([5, 5, 96, 256]), name='w2'),  # 5*5*96  256 filters\n",
        "    'w3': tf.Variable(tf.random.normal([3, 3, 256, 384]), name='w3'),\n",
        "    'w4': tf.Variable(tf.random.normal([3, 3, 384, 384]), name='w4'),\n",
        "    'w5': tf.Variable(tf.random.normal([3, 3, 384, 256]), name='w5'),\n",
        "    'wfc1': tf.Variable(tf.random.normal([6 * 6 * 256, 4096]), name='wfc1'),\n",
        "    'wfc2': tf.Variable(tf.random.normal([4096, 4096]), name='wfc2'),\n",
        "    'wout': tf.Variable(tf.random.normal([4096, 2]), name='wout')\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random.normal([96]), name='b1'),\n",
        "    'b2': tf.Variable(tf.random.normal([256]), name='b2'),\n",
        "    'b3': tf.Variable(tf.random.normal([384]), name='b3'),\n",
        "    'b4': tf.Variable(tf.random.normal([384]), name='b4'),\n",
        "    'b5': tf.Variable(tf.random.normal([256]), name='b5'),\n",
        "    'bfc1': tf.Variable(tf.random.normal([4096]), name='bfc1'),  # 4096\n",
        "    'bfc2': tf.Variable(tf.random.normal([4096]), name='bfc2'),  # 4096\n",
        "    'bout': tf.Variable(tf.random.normal([num_classes]), name='bout')  # 2\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "EA96MXL3rJqL"
      },
      "outputs": [],
      "source": [
        "def alex_net(x, weights, biases):\n",
        "    # reshape input to 227*227*3 size\n",
        "    x = tf.reshape(x, shape=[-1, 227, 227, 3])\n",
        "\n",
        "    print(\"###########################################################################\")\n",
        "    print(\"size of x is\")\n",
        "    print(x.shape)\n",
        "\n",
        "    # conv1\n",
        "    # kernel size=11*11, stride=4\n",
        "    conv1_in = tf.nn.conv2d(x, weights['w1'], strides=[1, 4, 4, 1], padding=\"SAME\")\n",
        "    conv1_in = tf.nn.bias_add(conv1_in, biases['b1'])   # y= xw+b\n",
        "    conv1 = tf.nn.relu(conv1_in)\n",
        "\n",
        "    # maxpool1   # kernel size 3*3, stride 2\n",
        "    maxpool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    print(\"###########################################################################\")\n",
        "    print(\"size after 1st conv layer) is \")\n",
        "    print(maxpool1.shape)\n",
        "\n",
        "    # conv2\n",
        "    # kernel 5*5, channels 256, stride 1\n",
        "    conv2_in = tf.nn.conv2d(maxpool1, weights['w2'], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "    conv2_in = tf.nn.bias_add(conv2_in, biases['b2'])\n",
        "    conv2 = tf.nn.relu(conv2_in)\n",
        "\n",
        "    # maxpool2\n",
        "    # kernel 3*3 stride 2\n",
        "    maxpool2 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "    print(\"###########################################################################\")\n",
        "    print(\"size after 2nd conv layer) is \")\n",
        "    print(maxpool2.shape)\n",
        "\n",
        "    # conv3\n",
        "    # kernel size=3*3, channels=384, stride 1\n",
        "    conv3_in = tf.nn.conv2d(maxpool2, weights['w3'], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "    conv3_in = tf.nn.bias_add(conv3_in, biases['b3'])\n",
        "    conv3 = tf.nn.relu(conv3_in)\n",
        "    print(\"###########################################################################\")\n",
        "    print(\"size after 3rd conv layer) is \")\n",
        "    print(conv3.shape)\n",
        "\n",
        "    # conv4\n",
        "    # kernel=3*3, channels=384, stride=1\n",
        "    conv4_in = tf.nn.conv2d(conv3, weights['w4'], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "    conv4_in = tf.nn.bias_add(conv4_in, biases['b4'])\n",
        "    conv4 = tf.nn.relu(conv4_in)\n",
        "    print(\"###########################################################################\")\n",
        "    print(\"size after 4th conv layer) is \")\n",
        "    print(conv4.shape)\n",
        "\n",
        "    # conv5\n",
        "    # kernel 3*3, channels=256, stride 1\n",
        "    conv5_in = tf.nn.conv2d(conv4, weights['w5'], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "    conv5_in = tf.nn.bias_add(conv5_in, biases['b5'])\n",
        "    conv5 = tf.nn.relu(conv5_in)\n",
        "\n",
        "    # maxpool5  # kernel 3*3, stride 2\n",
        "    maxpool5 = tf.nn.max_pool(conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "\n",
        "    print(\"###########################################################################\")\n",
        "    print(\"size after 5th conv layer) is \")\n",
        "    print(conv5.shape)\n",
        "    print(\"###########################################################################\")\n",
        "    print(\"size after 5th conv layer pooling) is \")\n",
        "    print(maxpool5.shape)\n",
        "\n",
        "    # Flatten layer\n",
        "    flat = tf.keras.layers.Flatten()(maxpool5)\n",
        "\n",
        "    # Fully connected layer 1 (fc6)\n",
        "    fc6 = tf.keras.layers.Dense(4096, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
        "                                bias_initializer=tf.keras.initializers.Zeros())(flat)\n",
        "\n",
        "    # Fully connected layer 2 (fc7)\n",
        "    fc7 = tf.keras.layers.Dense(4096, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
        "                                bias_initializer=tf.keras.initializers.Zeros())(fc6)\n",
        "\n",
        "    # Fully connected layer 3 (fc8)\n",
        "    fc8 = tf.keras.layers.Dense(num_classes, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
        "                                bias_initializer=tf.keras.initializers.Zeros())(fc7)\n",
        "\n",
        "    out = tf.nn.softmax(fc8)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "scrolled": true,
        "id": "rwMKdiDbrJqL",
        "outputId": "492cb38b-b2e5-4109-f048-b2763092a92e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.conv2d_32), but are not present in its tracked objects:   <tf.Variable 'w1:0' shape=(11, 11, 3, 96) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_32), but are not present in its tracked objects:   <tf.Variable 'b1:0' shape=(96,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.conv2d_33), but are not present in its tracked objects:   <tf.Variable 'w2:0' shape=(5, 5, 96, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_33), but are not present in its tracked objects:   <tf.Variable 'b2:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.conv2d_34), but are not present in its tracked objects:   <tf.Variable 'w3:0' shape=(3, 3, 256, 384) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_34), but are not present in its tracked objects:   <tf.Variable 'b3:0' shape=(384,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.conv2d_35), but are not present in its tracked objects:   <tf.Variable 'w4:0' shape=(3, 3, 384, 384) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_35), but are not present in its tracked objects:   <tf.Variable 'b4:0' shape=(384,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.conv2d_36), but are not present in its tracked objects:   <tf.Variable 'w5:0' shape=(3, 3, 384, 256) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_36), but are not present in its tracked objects:   <tf.Variable 'b5:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###########################################################################\n",
            "size of x is\n",
            "(None, 227, 227, 3)\n",
            "###########################################################################\n",
            "size after 1st conv layer) is \n",
            "(None, 28, 28, 96)\n",
            "###########################################################################\n",
            "size after 2nd conv layer) is \n",
            "(None, 13, 13, 256)\n",
            "###########################################################################\n",
            "size after 3rd conv layer) is \n",
            "(None, 13, 13, 384)\n",
            "###########################################################################\n",
            "size after 4th conv layer) is \n",
            "(None, 13, 13, 384)\n",
            "###########################################################################\n",
            "size after 5th conv layer) is \n",
            "(None, 13, 13, 256)\n",
            "###########################################################################\n",
            "size after 5th conv layer pooling) is \n",
            "(None, 6, 6, 256)\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='tf.nn.softmax_3/Softmax:0', description=\"created by layer 'tf.nn.softmax_3'\")\n"
          ]
        }
      ],
      "source": [
        "# Create the model\n",
        "model = alex_net(x, weights, biases)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rNT9UyDe-vUb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}